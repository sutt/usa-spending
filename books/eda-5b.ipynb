{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Analysis: New Transactions to Awards\n",
    "\n",
    "This notebook:\n",
    "1. Loads the most recent transaction and award datasets\n",
    "2. Identifies new awards vs modifications in transactions (using eda-3 methodology)\n",
    "3. Filters to only new transactions\n",
    "4. Joins new transactions to awards by award_id\n",
    "5. Analyzes match rate: how many transactions find their award vs not found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Most Recent Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Available Datasets ===\n",
      "Most recent transactions: transactions_normalized_2026-01-08_22-52-58.json\n",
      "Most recent awards: awards_normalized_2026-01-09_00-19-53.json\n"
     ]
    }
   ],
   "source": [
    "def find_most_recent_file(data_dir, pattern):\n",
    "    \"\"\"Find the most recent file matching pattern in data_dir\"\"\"\n",
    "    files = glob.glob(str(Path(data_dir) / pattern))\n",
    "    if not files:\n",
    "        return None\n",
    "    # Sort by modification time, most recent first\n",
    "    files.sort(key=lambda x: Path(x).stat().st_mtime, reverse=True)\n",
    "    return files[0]\n",
    "\n",
    "# Look for most recent normalized datasets\n",
    "data_dir = Path('../data/awards')\n",
    "\n",
    "transactions_file = find_most_recent_file(data_dir, 'transactions_normalized_*.json')\n",
    "awards_file = find_most_recent_file(data_dir, 'awards_normalized_*.json')\n",
    "\n",
    "print(\"=== Available Datasets ===\")\n",
    "if transactions_file:\n",
    "    print(f\"Most recent transactions: {Path(transactions_file).name}\")\n",
    "if awards_file:\n",
    "    print(f\"Most recent awards: {Path(awards_file).name}\")\n",
    "\n",
    "if not transactions_file or not awards_file:\n",
    "    raise FileNotFoundError(\"Need both transaction and award datasets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Transactions ===\n",
      "Loaded 7,952 transactions\n",
      "Shape: (7952, 22)\n",
      "Columns: 22\n"
     ]
    }
   ],
   "source": [
    "# Load transactions\n",
    "print(\"=== Loading Transactions ===\")\n",
    "with open(transactions_file, 'r') as f:\n",
    "    transactions_data = json.load(f)\n",
    "\n",
    "transactions_df = pd.DataFrame(transactions_data)\n",
    "\n",
    "print(f\"Loaded {len(transactions_df):,} transactions\")\n",
    "print(f\"Shape: {transactions_df.shape}\")\n",
    "print(f\"Columns: {transactions_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Awards ===\n",
      "Loaded 1,000 awards\n",
      "Shape: (1000, 18)\n",
      "Columns: 18\n"
     ]
    }
   ],
   "source": [
    "# Load awards\n",
    "print(\"=== Loading Awards ===\")\n",
    "with open(awards_file, 'r') as f:\n",
    "    awards_data = json.load(f)\n",
    "\n",
    "awards_df = pd.DataFrame(awards_data)\n",
    "\n",
    "print(f\"Loaded {len(awards_df):,} awards\")\n",
    "print(f\"Shape: {awards_df.shape}\")\n",
    "print(f\"Columns: {awards_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards_df.award_date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_df.award_amount > 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify New Awards vs Modifications\n",
    "\n",
    "Following the methodology from eda-3.ipynb:\n",
    "- **New awards**: `modification_number == '0'` OR `action_type_description == 'NEW'`\n",
    "- **Modifications**: Everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check key fields\n",
    "print(\"=== Transaction Fields for Filtering ===\")\n",
    "print(f\"\\nModification Number - Top 10:\")\n",
    "print(transactions_df['modification_number'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nAction Type Description - All values:\")\n",
    "print(transactions_df['action_type_description'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filter from eda-3\n",
    "new_transactions = transactions_df[\n",
    "    (transactions_df['modification_number'] == '0') | \n",
    "    (transactions_df['action_type_description'] == 'NEW')\n",
    "]\n",
    "\n",
    "modifications = transactions_df[\n",
    "    (transactions_df['modification_number'] != '0') & \n",
    "    (transactions_df['action_type_description'] != 'NEW')\n",
    "]\n",
    "\n",
    "print(\"=== Transaction Filtering Results ===\")\n",
    "print(f\"Total transactions: {len(transactions_df):,}\")\n",
    "print(f\"New transactions: {len(new_transactions):,} ({len(new_transactions)/len(transactions_df)*100:.1f}%)\")\n",
    "print(f\"Modifications: {len(modifications):,} ({len(modifications)/len(transactions_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nNew transactions total value: ${new_transactions['federal_action_obligation'].sum():,.2f}\")\n",
    "print(f\"New transactions avg value: ${new_transactions['federal_action_obligation'].mean():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.federal_action_obligation.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df[transactions_df.federal_action_obligation > 100_000].federal_action_obligation.sort_values(ascending=True)\n",
    "# new_transactions.federal_action_obligation > 0.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview: New Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample of new transactions\n",
    "print(\"=== Sample New Transactions ===\")\n",
    "new_transactions[[\n",
    "    'transaction_id', 'award_id', 'action_date', 'modification_number',\n",
    "    'action_type_description', 'federal_action_obligation', \n",
    "    'recipient_name', 'award_description'\n",
    "]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join New Transactions to Awards\n",
    "\n",
    "Now we'll join the new transactions to awards by `award_id` and analyze the match rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique award_ids in each dataset\n",
    "print(\"=== Award ID Coverage ===\")\n",
    "print(f\"Unique award_ids in new transactions: {new_transactions['award_id'].nunique():,}\")\n",
    "print(f\"Unique award_ids in awards dataset: {awards_df['award_id'].nunique():,}\")\n",
    "\n",
    "# Check for overlaps\n",
    "transaction_award_ids = set(new_transactions['award_id'])\n",
    "awards_award_ids = set(awards_df['award_id'])\n",
    "\n",
    "overlap = transaction_award_ids.intersection(awards_award_ids)\n",
    "only_in_transactions = transaction_award_ids - awards_award_ids\n",
    "only_in_awards = awards_award_ids - transaction_award_ids\n",
    "\n",
    "print(f\"\\nAward IDs in both datasets: {len(overlap):,}\")\n",
    "print(f\"Award IDs only in transactions: {len(only_in_transactions):,}\")\n",
    "print(f\"Award IDs only in awards: {len(only_in_awards):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the join\n",
    "print(\"=== Performing Left Join ===\")\n",
    "print(\"Joining new_transactions to awards on award_id...\")\n",
    "\n",
    "joined_df = new_transactions.merge(\n",
    "    awards_df,\n",
    "    on='award_id',\n",
    "    how='left',\n",
    "    suffixes=('_transaction', '_award'),\n",
    "    indicator=True\n",
    ")\n",
    "\n",
    "print(f\"\\nJoined dataframe shape: {joined_df.shape}\")\n",
    "print(f\"Columns: {joined_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.source_url_award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)   # show full text in cells\n",
    "pd.set_option(\"display.width\", 200)            # total display width\n",
    "pd.set_option(\"display.max_columns\", None)     # show all columns\n",
    "pd.DataFrame(joined_df.award_description_award)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[joined_df.award_description_transaction != joined_df.award_description_award]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = joined_df.federal_action_obligation - joined_df.award_amount > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = joined_df.federal_action_obligation - joined_df.award_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_df[tmp]\n",
    "tmp2[tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.award_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df.groupby('award_type').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Match Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the _merge indicator\n",
    "print(\"=== Join Results Analysis ===\")\n",
    "print(\"\\nMerge indicator breakdown:\")\n",
    "print(joined_df['_merge'].value_counts())\n",
    "\n",
    "# Calculate match rates\n",
    "matched = joined_df[joined_df['_merge'] == 'both']\n",
    "not_matched = joined_df[joined_df['_merge'] == 'left_only']\n",
    "\n",
    "print(f\"\\n=== MATCH RATE SUMMARY ===\")\n",
    "print(f\"Total new transactions: {len(new_transactions):,}\")\n",
    "print(f\"Transactions that found their award: {len(matched):,} ({len(matched)/len(new_transactions)*100:.1f}%)\")\n",
    "print(f\"Transactions that did NOT find their award: {len(not_matched):,} ({len(not_matched)/len(new_transactions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by value\n",
    "matched_value = matched['federal_action_obligation'].sum()\n",
    "not_matched_value = not_matched['federal_action_obligation'].sum()\n",
    "total_value = new_transactions['federal_action_obligation'].sum()\n",
    "\n",
    "print(\"=== MATCH RATE BY VALUE ===\")\n",
    "print(f\"Total value of new transactions: ${total_value:,.2f}\")\n",
    "print(f\"Value with matched awards: ${matched_value:,.2f} ({matched_value/total_value*100:.1f}%)\")\n",
    "print(f\"Value without matched awards: ${not_matched_value:,.2f} ({not_matched_value/total_value*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Match Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# By count\n",
    "counts = [len(matched), len(not_matched)]\n",
    "labels = [f'Found Award\\n({len(matched):,})', f'Award Not Found\\n({len(not_matched):,})']\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[0].pie(counts, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[0].set_title('Transaction to Award Match Rate (Count)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# By value\n",
    "values = [matched_value, not_matched_value]\n",
    "values_b = [v/1e9 for v in values]\n",
    "labels_val = [f'Found Award\\n(${values_b[0]:.1f}B)', f'Award Not Found\\n(${values_b[1]:.1f}B)']\n",
    "axes[1].pie(values, labels=labels_val, autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Transaction to Award Match Rate (Value)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Unmatched Transactions\n",
    "\n",
    "Why didn't some transactions find their awards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== UNMATCHED TRANSACTIONS ANALYSIS ===\")\n",
    "print(f\"\\nTotal unmatched: {len(not_matched):,}\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nSample unmatched transactions:\")\n",
    "print(not_matched[[\n",
    "    'transaction_id', 'award_id', 'action_date', 'modification_number',\n",
    "    'federal_action_obligation', 'recipient_name', 'award_type_transaction'\n",
    "]].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze unmatched by award type\n",
    "print(\"=== Unmatched Transactions by Award Type ===\")\n",
    "unmatched_by_type = not_matched.groupby('award_type_transaction').agg({\n",
    "    'transaction_id': 'count',\n",
    "    'federal_action_obligation': 'sum'\n",
    "}).sort_values('transaction_id', ascending=False)\n",
    "unmatched_by_type.columns = ['Count', 'Total Value']\n",
    "print(unmatched_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dates - maybe the awards are from different time periods?\n",
    "print(\"=== Date Range Comparison ===\")\n",
    "print(f\"\\nTransactions date range:\")\n",
    "print(f\"  Min: {transactions_df['action_date'].min()}\")\n",
    "print(f\"  Max: {transactions_df['action_date'].max()}\")\n",
    "\n",
    "print(f\"\\nAwards date range (award_date):\")\n",
    "# Filter out empty strings\n",
    "award_dates = awards_df[awards_df['award_date'] != '']['award_date']\n",
    "if len(award_dates) > 0:\n",
    "    print(f\"  Min: {award_dates.min()}\")\n",
    "    print(f\"  Max: {award_dates.max()}\")\n",
    "    print(f\"  Non-empty award_dates: {len(award_dates)} / {len(awards_df)}\")\n",
    "else:\n",
    "    print(\"  No non-empty award_dates found!\")\n",
    "\n",
    "print(f\"\\nAwards date range (start_date):\")\n",
    "print(f\"  Min: {awards_df['start_date'].min()}\")\n",
    "print(f\"  Max: {awards_df['start_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Matched Transactions\n",
    "\n",
    "For transactions that found their award, let's compare the data between transaction and award."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== MATCHED TRANSACTIONS ANALYSIS ===\")\n",
    "print(f\"Total matched: {len(matched):,}\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nSample matched transactions with awards:\")\n",
    "print(matched[[\n",
    "    'transaction_id', 'award_id', 'action_date', \n",
    "    'federal_action_obligation', 'award_amount',\n",
    "    'recipient_name_transaction', 'recipient_name_award'\n",
    "]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare amounts: transaction vs award\n",
    "# Note: transaction amount is the action amount, award amount is total award amount\n",
    "print(\"=== Transaction vs Award Amounts ===\")\n",
    "print(f\"\\nTransaction amounts (federal_action_obligation):\")\n",
    "print(f\"  Mean: ${matched['federal_action_obligation'].mean():,.2f}\")\n",
    "print(f\"  Median: ${matched['federal_action_obligation'].median():,.2f}\")\n",
    "print(f\"  Total: ${matched['federal_action_obligation'].sum():,.2f}\")\n",
    "\n",
    "print(f\"\\nAward amounts (award_amount):\")\n",
    "print(f\"  Mean: ${matched['award_amount'].mean():,.2f}\")\n",
    "print(f\"  Median: ${matched['award_amount'].median():,.2f}\")\n",
    "print(f\"  Total: ${matched['award_amount'].sum():,.2f}\")\n",
    "\n",
    "print(f\"\\nNote: Award amounts are typically larger because they represent\")\n",
    "print(f\"the total obligated amount for the entire award, while transaction\")\n",
    "print(f\"amounts represent individual actions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if recipient names match\n",
    "matched['recipient_match'] = matched['recipient_name_transaction'] == matched['recipient_name_award']\n",
    "\n",
    "print(\"=== Recipient Name Consistency ===\")\n",
    "print(f\"Transactions where recipient names match: {matched['recipient_match'].sum():,} ({matched['recipient_match'].sum()/len(matched)*100:.1f}%)\")\n",
    "print(f\"Transactions where recipient names differ: {(~matched['recipient_match']).sum():,} ({(~matched['recipient_match']).sum()/len(matched)*100:.1f}%)\")\n",
    "\n",
    "# Show examples of mismatches\n",
    "if (~matched['recipient_match']).sum() > 0:\n",
    "    print(\"\\nExamples of mismatched recipients:\")\n",
    "    mismatched = matched[~matched['recipient_match']][[\n",
    "        'award_id', 'recipient_name_transaction', 'recipient_name_award'\n",
    "    ]].head(10)\n",
    "    print(mismatched.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY FINDINGS: New Transactions to Awards Join Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. DATA VOLUMES\")\n",
    "print(f\"   - Total transactions loaded: {len(transactions_df):,}\")\n",
    "print(f\"   - New transactions (filtered): {len(new_transactions):,} ({len(new_transactions)/len(transactions_df)*100:.1f}%)\")\n",
    "print(f\"   - Total awards loaded: {len(awards_df):,}\")\n",
    "\n",
    "print(f\"\\n2. MATCH RATE\")\n",
    "print(f\"   - Transactions that found their award: {len(matched):,} ({len(matched)/len(new_transactions)*100:.1f}%)\")\n",
    "print(f\"   - Transactions that did NOT find award: {len(not_matched):,} ({len(not_matched)/len(new_transactions)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n3. MATCH RATE BY VALUE\")\n",
    "print(f\"   - Total value (new transactions): ${total_value:,.2f}\")\n",
    "print(f\"   - Matched value: ${matched_value:,.2f} ({matched_value/total_value*100:.1f}%)\")\n",
    "print(f\"   - Unmatched value: ${not_matched_value:,.2f} ({not_matched_value/total_value*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n4. AWARD ID OVERLAP\")\n",
    "print(f\"   - Unique award_ids in new transactions: {new_transactions['award_id'].nunique():,}\")\n",
    "print(f\"   - Unique award_ids in awards: {awards_df['award_id'].nunique():,}\")\n",
    "print(f\"   - Award IDs in both datasets: {len(overlap):,}\")\n",
    "print(f\"   - Award IDs only in transactions: {len(only_in_transactions):,}\")\n",
    "\n",
    "print(f\"\\n5. DATA CONSISTENCY (for matched records)\")\n",
    "if len(matched) > 0:\n",
    "    print(f\"   - Recipient names match: {matched['recipient_match'].sum():,} ({matched['recipient_match'].sum()/len(matched)*100:.1f}%)\")\n",
    "    print(f\"   - Recipient names differ: {(~matched['recipient_match']).sum():,} ({(~matched['recipient_match']).sum()/len(matched)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n6. IMPLICATIONS\")\n",
    "if len(not_matched) > 0:\n",
    "    not_matched_pct = len(not_matched)/len(new_transactions)*100\n",
    "    if not_matched_pct > 50:\n",
    "        print(f\"   ⚠️  HIGH MISMATCH RATE: {not_matched_pct:.1f}% of new transactions don't find awards\")\n",
    "        print(f\"   - Likely cause: Different time periods or different filtering criteria\")\n",
    "        print(f\"   - Awards endpoint uses award-level summaries (rolled up)\")\n",
    "        print(f\"   - Transactions endpoint has transaction-level detail\")\n",
    "    else:\n",
    "        print(f\"   ✓ GOOD MATCH RATE: {100-not_matched_pct:.1f}% of new transactions find their awards\")\n",
    "else:\n",
    "    print(f\"   ✓ PERFECT MATCH: All new transactions found their awards!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export matched and unmatched for further investigation\n",
    "output_dir = Path('../data/awards')\n",
    "\n",
    "matched_output = output_dir / 'matched_transactions_to_awards.csv'\n",
    "unmatched_output = output_dir / 'unmatched_transactions.csv'\n",
    "\n",
    "# Export matched (with selected columns to avoid duplication)\n",
    "matched_export = matched[[\n",
    "    'transaction_id', 'award_id', 'action_date', 'modification_number',\n",
    "    'federal_action_obligation', 'award_amount',\n",
    "    'recipient_name_transaction', 'recipient_name_award',\n",
    "    'award_type_transaction', 'awarding_agency_name_transaction'\n",
    "]]\n",
    "matched_export.to_csv(matched_output, index=False)\n",
    "print(f\"Exported {len(matched):,} matched records to: {matched_output}\")\n",
    "\n",
    "# Export unmatched\n",
    "unmatched_export = not_matched[[\n",
    "    'transaction_id', 'award_id', 'action_date', 'modification_number',\n",
    "    'federal_action_obligation', 'recipient_name_transaction',\n",
    "    'award_type_transaction', 'awarding_agency_name_transaction',\n",
    "    'award_description'\n",
    "]]\n",
    "unmatched_export.to_csv(unmatched_output, index=False)\n",
    "print(f\"Exported {len(not_matched):,} unmatched records to: {unmatched_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
